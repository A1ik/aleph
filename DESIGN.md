Iteration II
============

aleph/crawler
aleph/ingest
aleph/extract
aleph/fs

* [DONE] Document / Record - distinction, raw data support
* [DONE] Use database to store documents and records
* [DONE] Inline S3/FS support
* [DONE] Ingest mechanism for URLs
* [DONE] Ingest mechanism for bundled files
* Alerts / Subscriptions
* Testing
* tidbits

-----
* [DONE] Fix attributes facets
* Entity data model / schema-based validation
* [DONE] Spindle importer 
* [DONE] OpenNames importer
* [DONE] Fix entities facets
* [DONE] Upgrade bootstrap-ui
* Refactor QueryContext 
* [DONE] Rename List -> Watchlist
* Source facets
* Source modals

* Azerbaijan importer 
* Moldova importer 
* YL importer
-----




D.I.T.
======


* ElasticSearch indexer and query frontend

/etags
    name
    category
    aliases


/subscriptions
    > alert users about etags in ingestor input
    > 


/ingestors
    > harvest whole web sites
    > run a scraper
    > load raw data from some place



crawl.grano.cc/
    

    badguys
        /statements/
        /entities/
        /sets/

    archive
        /collections/ [list, edit, index]
        /query/
        /tag


"Osama bin Laden" ["Osama Bin Ladin", "Usama bin Laden"]





* Collections write API distinction
* Collections editor

* Lists + Entities model 
* Calais' "special" list and calais tagger
* Generic tagger 
* List editor and importer
